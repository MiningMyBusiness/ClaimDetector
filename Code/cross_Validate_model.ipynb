{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in feature matrices and class labels and test performance of Extremely random forest ExtraTreesClassifier\n",
    "\n",
    "Author: Kiran Bhattacharyya\n",
    "\n",
    "Revision: 5/11/18 - DRM - translate .py files into .ipynb, misc formatting \n",
    "\n",
    "\n",
    "1. loads in feature matrices and class labels from claim and not claim datasets (created with `feature_Preprocessing.ipynb`\n",
    "2. trains a ExtraTreesClassifier on the entire dataset to do feature selection\n",
    "3. orders the feature matrix by the order of increasing importance of features\n",
    "4. iteratively trains extra trees classifiers on increasing subsets of features with cross validation\n",
    "5. saves results of study as `CrossValidationResults_ExtraTrees_10estimators.pkl`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import relevant libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### define a function that perform cross validation with train-test splitting on a given dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RandomForestCrossVal(X, y, numCrossVals, testRat):\n",
    "    Accu_0 = np.zeros(numCrossVals)\n",
    "    Accu_1 = np.zeros(numCrossVals)\n",
    "    Accu_a = np.zeros(numCrossVals)\n",
    "    y = np.ravel(y)\n",
    "\n",
    "    for i in range(0,numCrossVals):\n",
    "        clf = ExtraTreesClassifier(n_estimators=10)\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=testRat)\n",
    "        clf.fit(X_train, y_train)\n",
    "        myPred_forest = clf.predict(X_test)\n",
    "        forestConfMat = confusion_matrix(y_test, myPred_forest)\n",
    "        Accu_0[i] = forestConfMat[0,0]/float(np.sum(forestConfMat[:,0]))\n",
    "        Accu_1[i] = forestConfMat[1,1]/float(np.sum(forestConfMat[:,1]))\n",
    "        Accu_a[i] = (forestConfMat[0,0] + forestConfMat[1,1])/float(len(y_test))\n",
    "\n",
    "    Accu_0_mean = np.mean(Accu_0)\n",
    "    Accu_0_std = np.std(Accu_0)\n",
    "    Accu_1_mean = np.mean(Accu_1)\n",
    "    Accu_1_std = np.std(Accu_1)\n",
    "    Accu_a_mean = np.mean(Accu_a)\n",
    "    Accu_a_std = np.std(Accu_a)\n",
    "\n",
    "    return Accu_0_mean, Accu_0_std, Accu_1_mean, Accu_1_std, Accu_a_mean, Accu_a_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "allFeatureName = pd.read_pickle('../Data/allFeatureNames.pkl') # get names of features\n",
    "needCiteFeat = np.load('../Data/NeedCiteFeatMat.npy') # feature matrix for citation needed dataset\n",
    "notClaimFeat = np.load('../Data/NotClaimFeatMat.npy') # feature matrix for no citation needed (not a claim) dataset\n",
    "\n",
    "# concatenate all data\n",
    "allFeats = np.concatenate((needCiteFeat, notClaimFeat), 0)\n",
    "allClass = np.concatenate((np.ones((len(needCiteFeat), 1)), np.zeros((len(notClaimFeat), 1))), 0)\n",
    "needCiteFeat = list() # clear data to save memory\n",
    "notClaimFeat = list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature number 2353 is character ']' and is irrelevant, an error in data pre processing\n",
    "allFeats[:,2353] = 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: I should do a quick check to make sure that nothing else slipped through pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# randomly reorder elements\n",
    "reOrder = np.random.permutation(len(allFeats))\n",
    "allFeats = allFeats[reOrder,:]\n",
    "allClass = allClass[reOrder,:]\n",
    "y = np.ravel(allClass)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm going to check if there is another way to do this easier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up the classification model\n",
    "\n",
    "DRM: I'll eventually add in some model selection and tuning here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### perform random forest classification to get feature importances\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = ExtraTreesClassifier(n_estimators=100)\n",
    "clf.fit(allFeats, y)\n",
    "featImp = clf.feature_importances_ # get feature importances\n",
    "featImpSort = np.argsort(featImp)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### rearrange dimensions so they are sorted by feature importance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allFeats_sort = np.zeros((len(allFeats), int(allFeats.shape[1])))\n",
    "featName_sort = list()\n",
    "for i in range(0,len(featImpSort)):\n",
    "    indx = featImpSort[-(i + 1)]\n",
    "    allFeats_sort[:,i] = allFeats[:,indx]\n",
    "    featName_sort.append(allFeatureName.FeatName[indx])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create subsets of dimensions to use based on importance 100-1000 so it is less than 100 fold of Ns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testRat = 0.2\n",
    "numCrossVals = 10\n",
    "dimsToTry = np.arange(100,1100,100)\n",
    "dimMeanAccu0 = np.zeros(len(dimsToTry))\n",
    "dimStdAccu0 = np.zeros(len(dimsToTry))\n",
    "dimMeanAccu1 = np.zeros(len(dimsToTry))\n",
    "dimStdAccu1 = np.zeros(len(dimsToTry))\n",
    "dimMeanAccua = np.zeros(len(dimsToTry))\n",
    "dimStdAccua = np.zeros(len(dimsToTry))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### perform 10-fold cross validation on each dimension\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,len(dimsToTry)):\n",
    "    dims = dimsToTry[i]\n",
    "    thisX = allFeats_sort[:,0:dims]\n",
    "    Accu_0_mean, Accu_0_std, Accu_1_mean, Accu_1_std, Accu_a_mean, Accu_a_std = RandomForestCrossVal(thisX, y, numCrossVals, testRat)\n",
    "    dimMeanAccu0[i] = Accu_0_mean\n",
    "    dimStdAccu0[i] = Accu_0_std\n",
    "    dimMeanAccu1[i] = Accu_1_mean\n",
    "    dimStdAccu1[i] = Accu_1_std\n",
    "    dimMeanAccua[i] = Accu_a_mean\n",
    "    dimStdAccua[i] = Accu_a_std\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create dataframe to save cross validation results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CrossVal_extraTrees_10estimators = pd.DataFrame({\n",
    "    'NumOfFeatDims': dimsToTry,\n",
    "    'NotClaimAccu': dimMeanAccu0,\n",
    "    'NotClaimAccuStd': dimStdAccu0,\n",
    "    'ClaimAccu': dimMeanAccu1,\n",
    "    'ClaimAccuStd': dimStdAccu1,\n",
    "    'OverallAccu': dimMeanAccua,\n",
    "    'OverallAccuStd': dimStdAccua\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## save dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CrossVal_extraTrees_10estimators.to_pickle('../Data/CrossValidationResults_ExtraTrees_10estimators.pkl')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
