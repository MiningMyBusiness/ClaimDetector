{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Builds and saves a model for later use based on claim and not claim dataset\n",
    "\n",
    "\n",
    "Author: Kiran Bhattacharyya\n",
    "\n",
    "Revision: 5/11/18 - DRM - translate .py files into .ipynb, misc formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import relevant libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allFeatureName = pd.read_pickle('../Data/allFeatureNames.pkl') # feature names\n",
    "needCiteFeat = np.load('../Data/NeedCiteFeatMat.npy') # feature matrix of claim dataset\n",
    "notClaimFeat = np.load('../Data/NotClaimFeatMat.npy') # feature matrix of not claim dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### concatenate all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allFeats = np.concatenate((needCiteFeat, notClaimFeat), 0)\n",
    "allClass = np.concatenate((np.ones((len(needCiteFeat), 1)), np.zeros((len(notClaimFeat), 1))), 0)\n",
    "needCiteFeat = list() # clear data to save memory\n",
    "notClaimFeat = list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I need to fix this bug in the saved data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature number 2353 is ']' and is irrelevant, an error in data pre-processing\n",
    "allFeats[:,2353] = 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### reorder elements\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reOrder = np.random.permutation(len(allFeats))\n",
    "allFeats = allFeats[reOrder,:]\n",
    "allClass = allClass[reOrder,:]\n",
    "y = np.ravel(allClass)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### perform random forest classification to get feature importances\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = ExtraTreesClassifier(n_estimators=100)\n",
    "clf.fit(allFeats, y)\n",
    "featImp = clf.feature_importances_ # get feature importances\n",
    "featImpSort = np.argsort(featImp) # sort feature importances\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### rearrange dimensions so they are sorted by feature importance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allFeats_sort = np.zeros((len(allFeats), int(allFeats.shape[1])))\n",
    "featName_sort = list()\n",
    "for i in range(0,len(featImpSort)):\n",
    "    indx = featImpSort[-(i + 1)]\n",
    "    allFeats_sort[:,i] = allFeats[:,indx]\n",
    "    featName_sort.append(allFeatureName.FeatName[indx])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### build a model with only 600 predictors since we found that accuracy does not change that much after the first 600 most important predictors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subFeats = allFeats_sort[:, 0:599]\n",
    "subFeatName = featName_sort[0:599]\n",
    "myModel = ExtraTreesClassifier(n_estimators=10)\n",
    "myModel.fit(subFeats, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## save the model to disk\n",
    "filename = '../Data/finalized_model.sav'\n",
    "pickle.dump(myModel, open(filename, 'wb'))\n",
    "\n",
    "## save the feature names, feature matrix, and class labels used to create the model\n",
    "np.save('../Data/Features_finalized_model.npy', subFeats)\n",
    "np.save('../Data/ClassLabels_finalized_model.npy', y)\n",
    "subFeatArr = np.array(subFeatName)\n",
    "np.save('../Data/FeatureName_finalized_model.npy', subFeatArr)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
