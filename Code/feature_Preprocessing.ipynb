{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature selection of citation needed and no citation needed (not a claim) datasets\n",
    "\n",
    "Author: Kiran Bhattacharyya\n",
    "\n",
    "Revision: 5/11/18 - DRM - translate .py files into .ipynb, misc formatting \n",
    "\n",
    "This code reads in the output from `featureExtract.py` OR `feature_Extract.ipynb`\n",
    "1. the part of speech filtered data sets including both words and parts of speech\n",
    "2. the counts\n",
    "\n",
    "All data is then saves as a pickle into three files: `NeedCiteFeatMat.pkl`, `NotClaimFeatMat.pkl`, and `allFeaturesNames.pkl`.\n",
    "\n",
    "Throughout this notebook, I'll refer to the data where citations are needed as \"Claim\", and the data where no citation is needed as \"NC\", meaning \"Not a Claim\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import relevant libraries\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load in data (output from `feature_Extract.ipynb`)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "NeedCite = pd.read_pickle('../Data/NeedCiteFilt.pkl') # part of speech filtered clauses and sentences that need citations\n",
    "NotClaim = pd.read_pickle('../Data/NotClaimFilt.pkl') # that do not need citations\n",
    "\n",
    "UniqWords = pd.read_pickle('../Data/UniqueWords.pkl') # word occurances in the above datasets\n",
    "UniqPOS = pd.read_pickle('../Data/UniquePOS.pkl') # part of speech occurances in the above datasets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### order words by most and least occurting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "totOccur_claim = float(np.sum(np.array(UniqWords.WordOccurClaim)))\n",
    "wordProp_claim = np.array(UniqWords.WordOccurClaim)/totOccur_claim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### divide occurance of each word by total number of occurances of all words to get a proportion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "totOccur_notClaim = float(np.sum(np.array(UniqWords.WordOccurNotClaim)))\n",
    "wordProp_notClaim = np.array(UniqWords.WordOccurNotClaim)/totOccur_notClaim\n",
    "\n",
    "wordProp_claim_sort = np.argsort(wordProp_claim)\n",
    "wordProp_notClaim_sort = np.argsort(wordProp_notClaim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get ratio of occurance proportions\n",
    "ratios greater than 1 suggests that the word or part of speech occurs (by proportion) more often in the Claim dataset while ratios less than 1 suggest that the word or part of speech occurs more often in the NC dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordProp_ratio = wordProp_claim/wordProp_notClaim\n",
    "wordProp_ratio_adj = wordProp_ratio/(totOccur_claim/totOccur_notClaim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### filter words based on occurance and ratio thresholds\n",
    "we want words that occur often and have large disparities in occurance in the two datasets it helps to plot the proportion against the ratio to see why I picked these thresholds e.g. plot(wordProp_claim, wordProp_ratio_adj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "propThresh = 0.000015 # occurance threshold (these may need to be changed )\n",
    "ratioThresh_hi = 1.25 # ratio threshold for more common than not claims\n",
    "ratioThresh_lo = 1/ratioThresh_hi # ratio threhsold for words less common that not claims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "isProp = wordProp_claim > propThresh\n",
    "lessThanInf = np.logical_and(wordProp_ratio_adj > ratioThresh_hi, wordProp_ratio_adj < np.Inf)\n",
    "bigThanZero = np.logical_and(wordProp_ratio_adj < ratioThresh_lo, wordProp_ratio_adj > 0)\n",
    "isRatio = np.logical_or(lessThanInf, bigThanZero)\n",
    "isInRegion = np.logical_and(isProp, isRatio)\n",
    "totWords = np.sum(isInRegion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get words that have high probabilities of occurance and large or small ratios\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "isInRegionIndx = [j for j, x in enumerate(isInRegion) if x] # grab index of words\n",
    "uniqWords_filt = list()\n",
    "for indx in isInRegionIndx:\n",
    "    uniqWords_filt.append(UniqWords.UniqueWords[indx])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### each filtered sentence will be represented as a binary vector where each element signifies if a word or part-of-speech occurs in the sentence or not\n",
    "\n",
    "initialize lists/vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allFeatures = list()\n",
    "allFeatures.append(uniqWords_filt)\n",
    "allFeatures.append(UniqPOS.UniquePOS)\n",
    "allFeature_flat = [item for sublist in allFeatures for item in sublist]\n",
    "needCiteFeats_word = np.zeros((len(NeedCite), totWords))\n",
    "needCiteFeats_POS = np.zeros((len(NeedCite), len(UniqPOS)))\n",
    "needCiteClass = np.ones((len(NeedCite), 1))\n",
    "notClaimFeats_word = np.zeros((len(NotClaim), totWords))\n",
    "notClaimFeats_POS = np.zeros((len(NotClaim), len(UniqPOS)))\n",
    "notClaimClass = np.zeros((len(NeedCite), 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### go through each sentence in list of sentences and populate feature vectors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,len(NeedCite)):\n",
    "    thisSent = NeedCite.NeedCiteWord[i]\n",
    "    thisPOSs = NeedCite.NeedCitePOS[i]\n",
    "    for j in range(0,totWords):\n",
    "        thisWord = uniqWords_filt[j]\n",
    "        if thisWord in thisSent:\n",
    "            needCiteFeats_word[i,j] = 1\n",
    "    for k in range(0,len(UniqPOS)):\n",
    "        thisPOS = UniqPOS.UniquePOS[k]\n",
    "        if thisPOS in thisPOSs:\n",
    "            needCiteFeats_POS[i,k] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,len(NotClaim)):\n",
    "    thisSent = NotClaim.NotClaimWord[i]\n",
    "    thisPOSs = NotClaim.NotClaimPOS[i]\n",
    "    for j in range(0,totWords):\n",
    "        thisWord = uniqWords_filt[j]\n",
    "        if thisWord in thisSent:\n",
    "            notClaimFeats_word[i,j] = 1\n",
    "    for k in range(0,len(UniqPOS)):\n",
    "        thisPOS = UniqPOS.UniquePOS[k]\n",
    "        if thisPOS in thisPOSs:\n",
    "            notClaimFeats_POS[i,k] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create full feature matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NeedCite_fullFeats = np.concatenate((needCiteFeats_word, needCiteFeats_POS), 1)\n",
    "NotClaim_fullFeats = np.concatenate((notClaimFeats_word, notClaimFeats_POS), 1)\n",
    "allFeatures = pd.DataFrame({\n",
    "    'FeatName': allFeature_flat\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## save feature matrices and feature names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('../Data/NeedCiteFeatMat.pkl', NeedCite_fullFeats)\n",
    "np.save('../Data/NotClaimFeatMat.pkl', NotClaim_fullFeats)\n",
    "allFeatures.to_pickle('../Data/allFeatureNames.pkl')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
